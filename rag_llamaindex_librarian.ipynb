{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUjEsgSaDvKd",
        "outputId": "42653bfd-a3c7-4307-b5df-f6ff3666e417"
      },
      "outputs": [],
      "source": [
        "#!brew install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8H5gtcu5DvKg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\miniconda3\\envs\\Book_AI_Env\\Lib\\site-packages\\ebooklib\\epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
            "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "loader = SimpleDirectoryReader(\n",
        "    input_dir=\"./test/\",\n",
        "    recursive=True,\n",
        "    required_exts=[\".epub\"],\n",
        ")\n",
        "\n",
        "documents = loader.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E9bRbVEcDvKh"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hvTIhMolDvKh"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from llama_index.llms.openai import OpenAI\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "llm_openai = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "query_engine = index.as_query_engine(llm=llm_openai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "6xn-JIg4DvKh",
        "outputId": "e5d6e86f-d452-46c9-f6c4-b13461ab9cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**VOLUME II—COSETTE**  \n",
            "**BOOK FIRST—WATERLOO**  \n",
            "**BOOK SECOND—THE SHIP ORION**\n"
          ]
        }
      ],
      "source": [
        "print(query_engine.query(\"What are the titles of all the books available? Show me the context used to derive your answer.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yCHJ_eODDvKi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mr. Darcy dislikes Wickham due to Wickham's actions and behavior, which have led to a strained relationship between them. Events such as Wickham's past behavior towards Darcy, including spreading false information about him, and Wickham's pursuit of Miss Darcy's fortune have contributed to the animosity between the two characters.\n"
          ]
        }
      ],
      "source": [
        "print(query_engine.query(\"Why does Darcy dislike Wickham, and what events contribute to their animosity?'?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
